## 前言

我是先将三篇文章看完一遍后，第二遍才做笔记。因此，对于两篇papers的实验部分，我读第一遍时觉都是在测试和比较Sentistrength(2)与其他情感分析方法或机器学习算法的性能，这和我们的作业内容似乎没什么重要关系，加上实验内容挺复杂的，所以第二遍没有仔细看，相关内容的笔记记的很少。

## 社交网络情感强度检测

#### 介绍

评估了sentistrength算法的一个改进版，称为sentistrength2，使用直接的情感指示来检测社交网络的情感强度，而不是利用反映主题的间接情感指示。在六个不同的社交网络数据集上进行了实验，在有监督和无监督的情况下，表现均优于基线方法，但并不总是优于利用间接情绪指标的机器学习方法。

传统的情感分析方法分析社交文本的问题：

* 需要人类编码的数据来作为训练输入和评估；

* 情感分析是领域依赖的，分类器用于不同于训练的数据集往往结果较差；

* 可能使用情绪的间接指标，为社会科学研究提供误导性结果。

综上所述，关键是要使用只允许利用情感的直接指标的分类器。这可以通过词汇方法实现，即主要通过从已知的带有情感的单词或短语的词典中识别术语来进行情感分析。

* 当前论文假设积极和消极的情感可以共存，解决的情感强度检测问题涉及对文本中的积极情感强度和消极情感强度进行评估。

* sentiment items会与默认的强度相关联，这是本文的重点。

sentistrength 旨在识别简短的非正式社交网络文本中的积极和消极情绪的强度。

### 情绪分析

情感分析任务：主观性和极性检测

方法：

* 选择一种机器学习算法和一种从文本中提取特征的方法，然后用人工编码的语料库训练分类器；

* 种子词；

这些方法都有可能识别间接情感词。

#### 词汇的算法

从一组已知的情感倾向的现有术语开始，然后使用一种算法根据这些单词的出来来预测文本的情感。

* 与senti-strength最相似的SO-CAL。

* 如果目标是情感强度检测而不是极性或主观性检测，那么词典很可能包含了人类估计的情感权重。

* 极性检测可以被认为是识别情感组，更深层次的句法分析可能在非正式的社交网络中不起作用。

#### sentistrength2

snetistrength是一个基于词典的分类器，利用附加的语言学信息和规则来检测短文非正式英语文本中的情感强度。对每个文本，情感强度输出是两个整数。最初版本只在Myspace上进行了测试，新版本被开发以应对更广泛的文本类型。主要变化是对否定术语的词典进行了重大扩展，旨在解决sentistrength在负面情感强度检测中相对较弱的性能问题。在版本二中地变化：

* 用以上否定词内容扩展了情绪术语表；

* 许多术语变成通配符，并添加了排除项；

* 否定的负面词汇变成中性而不是积极；

* 习语表被扩展；

* 问题中否定情感的特殊规则被排除。

### 研究问题

评估各种不同的在线上下文中的sentistrength2，以确定它作为社交网络的通用情感强度检测算法的可行性。

* 目标是可行性，不是最优性能，要求结果在所有数据集的积极和消极情感上都拥有统计学上的强正相关性。不需要训练数据的无监督版本的sentistrength2是正确的。

* 次要目标是评估其与其他的利用间接情感术语的方法相比的表现，以及它在哪些类型的社交网络数据上表现最好。标准的机器学习方法用于这一比较。

#### 方法和数据

* 每个数据源的文本由1~3名不同的人独立操作。

* 每种算法都是用10折交叉验证测试了30次。

#### 语料库的统计数据和整体情绪分布

* 数据集大小差异显著。

* 积极和消极情绪强度的比例存在重要的差异。

### 结果

* sentistrength在所有数据集上都超过了负面情绪强度的基线准确性，正面情绪强度上在大部分数据集上也是如此。

* 机器学习方法，往往优于sentistrength。

#### 局限性

* 实验不详尽，仍可能存在不适用的社交网络环境类型，特别是含有讽刺等不寻常语言的环境。

* 并非所有的数据集都有三个不同的编码人员编码。

* 机器学习利用与情感相关的主题，即间接情感术语。

* sentistrength不能保证只使用直接情感术语。

* 机器学习的性能可能被夸大，因为每种情况只使用了虽好的结果、

### 结果

sentistrength适用于社交网络中的情感强度检测，即使是在无监督的版本，也推荐使用仅林勇直接情感词的应用。

## 短文本中的情感强度检测

sentistrength 使用新的方法来利用网络空间事实上的语法和拼写风格，从非正式英语文本中提取情感强度。

### 介绍

* 对于某些应用，有必要检测积极和消极两种情绪，以及它们的强度。

* 在线情感检测的一个复杂因素是电子通信媒体中糟糕的语法和拼写规则，但典型的语言情感分析程序依赖标准拼写和语法。

* snetistrength 采用多种新颖的方法从简短的非正式电子文本中同时提取正面和负面情感强度。它使用带有相关强度测量的情感词词典，并利用一系列公认的非标准拼写和其他表达情感的常见文本方法。它最初是在MySpace评论集上进行开发和测试的。

### 背景和相关工作

#### 意见挖掘。

阶段:

* 输入文本被分成几个部分

* 分析主管句以检测情感极性

* 提取表达意见的对象

通常使用机器学习来识别与积极和消极情绪相关联的一般特征，如单词、词性、n元语法的子集，表情符号等。两个重复出现的机器学习问题是特征选择和分类算法选择。

#### 检测多种情绪

积极和消极情绪可以共存，并且在许多情况下是相对独立的，将情绪视为可单独测量的积极和消极成分似乎是合理。

#### 情感强度检测

### 数据集与人类对情绪强度的判断

使用人类编码者的主观判断，以五分制对积极和消极情绪进行判断。使用编码者的平均值作为黄金标准。

#### SentiStrength 情感强度检测算法

该情绪检测算法是在用于试点测试的2600个MySpace分类的初始集上开始的。

关键要素：

* 算法的核心是情感词强度表。

* 通过训练算法修改上述默认手动单词表，以优化情感单词强度。

* ”小姐“。

* 拼写校正算法通过包含重复字母来识别拼写错误的单词的标准拼写。

* 增强词列表。

* 否定词列表，反转。

* 只要有至少两个额外的字母，超过正确拼写所需的重复字母被用来给情绪词增加1的强度。

* 表情列表。

* 任何带有感叹号的句子都被分配了最低2的正面强度。

* 负面情绪在提问中被忽略。

上述因素分别应用于每个句子，句子被分配了最积极和最消极的情绪。每条总体评论都被分配了最积极的句子情绪和最消极的句子情绪。

### 实验

* SentiStrength在一组1041条MySpace评论上进行测试。平均值被用作黄金标准。使用了10倍交叉验证方法。

* 将结果与与随机分配和 基线多数类分类，还有Weka中的一系列标准机器学习分类算法进行了比较。

* 使用情感单词列表中每个单词的频率作为特征集。用于比较的扩展特征集包括长度为1-3的n元语法。

#### 与机器学习、扩展功能集的比较

特征选择改善了所有方法的结果每种方法的最佳特征集大小与SentiStrength的比较。使用具有最佳特征数量的扩展特征集的机器学习分类器，如通过信息增益所选择的，明显不如SentiStrength准确。SentiStrength还具有与黄金标准最高的相关性、最低的平均百分比误差和最高的一级精度。因此，它始终比其他算法表现更好。对于负面情绪强度，大多数方法给出了非常相似的结果，一些方法给出了比sentistrength更好的结果。

#### 机器学习的特征集比较-积极情绪强度

我看完后感觉和作业没有关系，于是没有笔记。

#### SentiStrength版本比较

实验结果没有提供令人信服的证据来证明任何变化比标准方法更好或更差。明显改善了它的变体并不比它健壮。

SentiStrength的主要优势在于其适应各种非正式文本变化的规则的综合效果，以及使用术语优势列表和识别任何评论中最强的正面和负面术语的整体方法。

### 讨论的结论

* 主要贡献：
  
  * 优化情感术语权重的机器学习方法；
  
  * 从文本中的非标准拼写中提取情感的方法；
  
  * 以及相关的拼写纠正方法；

* SentiStrength 在识别积极情绪的强度方面，显著高于最佳标准机器学习方法。

* SentiStrength相对成功的主要原因似乎是解码非标准拼写的程序和增强单词强度的方法，这是其性能的主要原因。

## SentiStrength Manual

### 介绍

### 核心功能

使用一套字典和若干启发式规则对文本进行情感分析。

EmotionLookupTable。对单词和通配符分配请安分数。

IdiomLookupTable。对短语分配分数。

BoosterWordList。包含增强或降低后续词的情绪的词。

NegatingWordList。包含反转后续情感词的词。

EmotionLookupTable。表情符号列表。

### 其他功能

SentiStrength最初是以jar包的形式发布的。

### 完成不同的分类任务

SentiStrength可以对单个文本或多个文本进行分类，并且可以以多种不同的方式调用。

* 对单个文本进行分类。
  
  * text[text to process]。

* 对文件中的所有文本进行情感分类【包括准确性评估】。
  
  * input[filename]。

* 对文件或者文件夹中某一栏的文本进行分类。
  
  * annotateCol [col# 1..] inputFolder[foldername]  fileSubstring [text]

* 在一个端口监听要分类的文本。
  
  * listen[port number to listen at - call OR

* 从命令行交互运行。
  
  * cmd (can also set options and sentidata folder)

* 处理标准输入并发送到标准输出
  
  * stdin (can also set options and sentidata folder)

* 语言数据文件夹的位置
  
  * sentidata [folder for SentiStrength data (end in slash, no spaces)]

* 情感术语权重的位置
  
  * EmotionLookupTable [filename (default: EmotionLookupTable.txt）

* 输出文件夹的位置
  
  * outputFolder [foldername where to put the output (default: folder of input)]

* 输出的UC-20文件扩展名
  
  * resultsextension [file-extension for output (default _out.txt)]

* 分别对正面(1到5)和负面(-1到5)情绪强度进行分类

* 使用三元分类法(阳性-阴性-中性)
  
  * trinary (report positive-negative-neutral classification instead)

* 使用二元分类法(正-负)
  
  * binary (report positive-negative classification instead)

* 使用单一正负标度分类
  
  * scale (report single -4 to +4 classification instead)

### 解释分类

* explain

设置分类算法参数

* alwaysSplitWordsAtApostrophes 拆分

* noBoosters (ignore sentiment booster words (e.g., very)) 无加强

* noNegatingPositiveFlipsEmotion (don't use negating words to flip +ve words) 不用否定词反转

* noNegatingNegativeNeutralisesEmotion (don't use negating words to neuter -ve words) 不用否定词中性化

* negatedWordStrengthMultiplier (strength multiplier when negated (default=0.5)) 求反时的强度乘数

* maxWordsBeforeSentimentToNegate (max words between negator & sentiment word (default 0)) 否定词和情感词之间的最大字数

* noIdioms (ignore idiom list) 忽略习语表

* questionsReduceNeg (-ve sentiment reduced in questions) 问题减少负面情绪

* noEmoticons (ignore emoticon list) 无表情图标
  
  。。。。

### 提高SentiStrength的准确性(2)

* 优化现有情感术语的情感强度
  
  * optimise [Filename for optimal term strengths (e.g. EmotionLookupTable2.txt)]

* 建议新的情感术语(来自错误分类文本中的术语)
  
  * termWeights

### 机器学习评估

* train (evaluate SentiStrength by training term strengths on results in file). An input file of 500+ human classified texts is also needed - e.g

#### 评估选项

* all  测试上述分类算法参数中列出的所有选项变体

* tot 通过正确分类的数量而不是分类差异的总和进行优化

* iterations [number of 10-fold iterations (default 1)] 迭代次数

* minImprovement [min extra correct class. to change sentiment weights (default 2)] 设置在训练阶段调整术语权重所需的额外正确分类的最小数量。

* multi [# duplicate term strength optimisations to change sentiment weights (default 1)] 术语权重不是被优化一次，而是从起始值被优化多次，然后取这些权重的平均值，并被优化和用作最终优化的术语强度。
  
  


